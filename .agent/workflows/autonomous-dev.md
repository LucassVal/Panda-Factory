---
description: Autonomous Multi-Agent Development Pipeline with Debate and Handoff
---

# ğŸ¤– AUTONOMOUS MULTI-AGENT WORKFLOW

## Overview

This workflow orchestrates multiple AI agents (Gemini, Claude Sonnet, Claude Opus) working autonomously with debate, critique, and handoff - no human intervention until final delivery.

---

## Usage

```
/autonomous-dev [PROJECT_NAME] [BRIEF_DESCRIPTION]
```

Example:

```
/autonomous-dev "Trading Bot" "Um bot de trading em Python com anÃ¡lise tÃ©cnica"
```

---

## ğŸ“‹ WORKFLOW STEPS

### STEP 1: PLANNING (Architect Agent)

**Agent:** @Gemini_3_Pro or Lead Architect

**Input:**

- Project description
- Files in `/docs` folder
- Any protocol files

**Actions:**

1. Read all protocol/context files
2. Design complete architecture
3. Create file structure
4. Define interfaces and data flow

**Output:**

```
ğŸ“„ architecture.md
   - System overview
   - Component diagram (ASCII/Mermaid)
   - File structure
   - API contracts
   - Data models
```

**Handoff:** "âœ… STEP 1 COMPLETE. @Auditor, critique this architecture."

---

### STEP 2: AUDIT (Critic Agent)

**Agent:** @Claude_Sonnet or Senior Reviewer

**Input:**

- `architecture.md`

**Actions:**

1. Review for logic flaws
2. Check security vulnerabilities
3. Analyze performance bottlenecks
4. Validate scalability

**Decision Tree:**

```
IF critical_issues > 0:
   â†’ Tag: "ğŸ”´ REFAZER" + detailed feedback
   â†’ Return to STEP 1

ELSE IF minor_issues > 0:
   â†’ Tag: "ğŸŸ¡ APROVADO COM RESSALVAS"
   â†’ Create test_plan.md with caveats
   â†’ Proceed to STEP 3

ELSE:
   â†’ Tag: "ğŸŸ¢ APROVADO"
   â†’ Create test_plan.md
   â†’ Proceed to STEP 3
```

**Output:**

```
ğŸ“„ test_plan.md
   - Unit test cases
   - Integration test scenarios
   - Edge cases
   - Performance benchmarks
```

**Handoff:** "âœ… STEP 2 COMPLETE. @Executor, build this."

---

### STEP 3: EXECUTION (Builder Agent)

**Agent:** @Claude_Opus or Implementation Specialist

**Input:**

- `architecture.md`
- `test_plan.md`

**Actions:**

1. Create all source files
2. Implement all functions
3. Add error handling
4. Include inline comments
5. Create README with usage

**Output:**

```
ğŸ“„ src/*.py (or appropriate language)
ğŸ“„ tests/*.py
ğŸ“„ README.md
ğŸ“„ requirements.txt (if applicable)
```

**Final Delivery:** "âœ… STEP 3 COMPLETE. Code ready for review."

---

## ğŸ”„ ITERATION PROTOCOL

If any step fails:

```
STEP N fails â†’ Return to STEP N-1 with tag "RETRY" + reason
Max retries per step: 2
If max retries exceeded: Escalate to human
```

---

## ğŸ“ EXPECTED FILE STRUCTURE

```
project-name/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md    (Step 1 output)
â”‚   â”œâ”€â”€ test_plan.md       (Step 2 output)
â”‚   â””â”€â”€ audit_log.md       (Review notes)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ core/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_main.py
â”‚   â””â”€â”€ test_core.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ·ï¸ COMMUNICATION TAGS

| Tag                  | Meaning                             |
| -------------------- | ----------------------------------- |
| `âœ… STEP N COMPLETE` | Step finished successfully          |
| `ğŸ”´ REFAZER`         | Critical issues, redo previous step |
| `ğŸŸ¡ RESSALVAS`       | Minor issues, proceed with caution  |
| `ğŸŸ¢ APROVADO`        | Fully approved                      |
| `ğŸ”„ RETRY`           | Retry current step                  |
| `ğŸš¨ ESCALATE`        | Needs human intervention            |

---

## ğŸ’¡ TIPS

1. **Be specific** in project description
2. **Include context files** in /docs before starting
3. **Define success criteria** upfront
4. **Set constraints** (language, framework, etc.)

---

## TEMPLATE: Initial Prompt

```markdown
OBJECTIVE: Develop [PROJECT_NAME]
BRIEF: [2-3 sentence description]
CONSTRAINTS:

- Language: [Python/JS/Rust]
- Framework: [if any]
- Must include: [requirements]

MODE: Autonomous Debate & Handoff

CONTEXT FILES:

- /docs/protocol.md
- /docs/examples/

START: Step 1 with @Architect
```
